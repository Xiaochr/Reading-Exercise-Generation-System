# Reading-Exercise-Generation-System

Codes for paper *Evaluating Reading Comprehension Exercises Generated by LLMs: A Showcase of ChatGPT in Education Applications*. 

## System Interface

We use *Vue.js* to build our system interface. First, you need to prepare basic requirements (node.js, npm, etc.) of Vue. Also, we do not include the *node_modules* folder in this repository. Before running the front-end service, necessary packages need to be installed (element-plus, vue-axios, etc.). 

Running front-end service:

```bash
cd ./reading-demo
npm install
npm run serve
```

## System Backend

We implement the backend using *Django*. The OpenAI API is not included in this repository, you need to enter it in `.\readingback\app\views.py`, or just try our [online demo](http://8.216.54.243:8083/). 

Running backend service: 

```bash
cd ./readingback
python manage.py runserver
```

## GPT-2 Baseline

The codes for the fine-tuned GPT-2 + PPLM baseline described in the paper are in `.\gpt2_baseline\` folder, including: 
- *gpt2_finetune.py*: fine-tuning GPT-2 medium with the reading material datasets
- *pplm_tune.py*: tune PPLM to find its optimal hyper-parameters for different topic keyword lists in 
- *passage_gen_example.py*: generating example passages


Please install PPLM (See more guidance in [the original PPLM repository](https://github.com/uber-research/PPLM)) and other required packages.

```bash
git clone https://github.com/uber-research/PPLM.git
pip install -r requirements.txt
```

Due to the confidentiality of educational resources, we are not able to publicly offer the access to the dataset. 

Also, we are not allowed by the anonymous policy to offer explicit Google Drive links so far, and the model files are too large to upload directly in the paper submission page. Nonetheless, the access to our fine-tuned GPT-2 model will be provided immediately after the anonymous stage. 

